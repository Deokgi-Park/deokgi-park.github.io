---
title: "[온프레미스 환경] 쿠버네티스 및 CI/CD 구축기"
date: 2025-06-27
toc: true
toc_label: "쿠버네티스 구축"
toc_icon: "list-squares"
categories: intro
tags: [k8s, k3s, post]
auther_profile: true
---

## [온프레미스 환경] 쿠버네티스 및 CI/CD 구축기

### 01. 컨테이너 엔진 설치

#### 1) 도커 설치

> 📝 **설명** : 쿠버네티스 환경에서 이미지를 가져오거나 관리하고 컨테이너 환경에서 실행시키기 위해 컨테이너 엔진을 설치해야한다.

> **➡️ 컨테이너 엔진/런타임 종류**
>
> **도커 엔진 (Docker Engine):**
> 가장 널리 사용되는 컨테이너 엔진.
> docker CLI와 통합되어 컨테이너 이미지 빌드, 배포, 실행 지원.
> kubernetes와 함께 사용 가능하지만, 1.20 버전 이후 Kubernetes에서는 기본 런타임에서 제외.
> **_(Podman과 CRI-O를 병행하여 사용 하는 것이 현재 보통)_**
>
> **CRI-O:**
> Kubernetes 전용으로 설계된 컨테이너 런타임.
> Open Container Initiative(OCI) 표준을 따름.
> containerd와 유사한 성능을 제공하며, Kubernetes와 긴밀하게 통합됨.
>
> **Podman:**
> 무데몬(Daemonless) 아키텍처를 특징으로 함.
> Docker와 CLI 호환성을 제공하며, 루트리스(rootless) 컨테이너 실행 가능.
> 쿠버네티스의 Pod 개념에서 사용하기 위한 컨테이너 엔진

> **💻 수행** : 각 리눅스 운영 체제에 맞는 명령어를 통해 **_docker_** 혹은 **_podman_** 을 설치

```bash
# 아래는 Rocky Linux에서 docker 설치 기준

# 패키지 관리 도구 업데이트
sudo dnf update -y --allowerasing

# 패키지 관리 유틸 설치
sudo dnf install -y yum-utils

# 패키지 관리 유틸에 도커 저장소 설정 진행
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# 도커 관련 패키지 설치
sudo dnf install -y docker-ce docker-ce-cli containerd.io --allowerasing
```

#### 2) 도커 실행 상태 체크

```bash
# 도커 실행 상태 체크
sudo systemctl status docker
```

```vim
[hso10@oracle ~]$ sudo systemctl status docker
● docker.service - Docker Application Container Engine
   Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disab>
   Active: inactive (dead)
     Docs: https://docs.docker.com

 6월 26 17:52:38 oracle dockerd[2387592]: time="2025-06-26T17:52:38.246736550+09:00" leve>
 6월 26 17:52:39 oracle dockerd[2387592]: time="2025-06-26T17:52:39.508974532+09:00" leve>
 6월 30 12:53:50 oracle dockerd[2387592]: time="2025-06-30T12:53:50.469760843+09:00" leve>
 6월 30 12:55:30 oracle dockerd[2387592]: time="2025-06-30T12:55:30.694143697+09:00" leve>
 6월 30 12:56:06 oracle systemd[1]: Stopping Docker Application Container Engine...
 6월 30 12:56:06 oracle dockerd[2387592]: time="2025-06-30T12:56:06.290388589+09:00" leve>
 6월 30 12:56:06 oracle dockerd[2387592]: time="2025-06-30T12:56:06.291885577+09:00" leve>
 6월 30 12:56:06 oracle dockerd[2387592]: time="2025-06-30T12:56:06.292504762+09:00" leve>
 6월 30 12:56:06 oracle systemd[1]: docker.service: Succeeded.
 6월 30 12:56:06 oracle systemd[1]: Stopped Docker Application Container Engine.
```

> **_docker.service: Succeeded_** 로 상태 체크

#### 3) 도커 미실행 시 실행 명령어

```bash
  sudo systemctl start docker
```

### 02. minikube

> **_온프레미스 환경에서 쿠버네티스 서비스를 위한 경량화된 쿠버네티스_**
> => kubeadm 등도 사용 가능하나 설치가 쉬운 minikube 기준으로 작성

#### 1) minikube 설치

> [minikube 공식문서](https://minikube.sigs.k8s.io/)

```bash
# 공식 문서 Linux 64 아키텍쳐 설치 방법
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-latest.x86_64.rpm
sudo rpm -Uvh minikube-latest.x86_64.rpm
```

#### 2) minikube 실행

```bash
##### - Docker 기준 실행
minikube start --driver=docker

##### - Podman 기준 실행
minikube start --driver=podman --container-runtime=cri-o
```

> **❗ 문제 발생 시 minikube 제거 후 재시작 방법**

```bash
# 해당 명령어 수행 시 동작되는 서비스, deployment, pod 등이 종료됨으로 유의하여 작업 필요
# pod는 컨테이너로 휘발성이 있음으로 설정이나 pod 내 생성 파일 등의 유실에 주의할 것
# => 별도의 볼륨(PV) 등을 설정하여 유실되지 않게 해야함
minikube delete
minikube start --driver=docker
```

#### 3) minikube kubectl 명령어 별칭 등록

> **minikube kubectl(쿠버네티스 조작어)를 약어로 명령어 사용을 위해 아래와 같은 설정 진행**

> **kubectl : Kubernetes 클러스터를 관리하고 상호작용하기 위해 사용하는 명령줄 도구**

```bash
# .bashrc 와 같은 리눅스 사용자 설정 파일에 셋팅한다
alias kubectl="minikube kubectl --"
```

### 03. 서비스 방식 설정

#### 1) 해당 서버가 외부 IP를 가진 서버의 경우

> **아래는 예상도로 실제 구성해보지 않음**

![alt text](/assets/images/외부IP_minikube.png)

#### 2) 해당 서버가 내부 IP를 가진 서버의 경우

> **현 작성글은 아래 구성을 토대로 작성
> => 내부IP 대역 : 192.168.0.0/16, 172.16.0.0/12, 10.0.0.0/8**

![alt text](/assets/images/내부IP_minikube.png)

```bash
# 미니쿠버의 IP 확인 명령어
minikube ip

# 미니쿠버의 addon(확장)  list 확인
# 설치 전
minikube addons list
#|ingress |minikube |disabled |Kubernetes |

# 설치 명령어 수행
minikube addons enable ingress

# 대시보드 설치(옵션)
minikube addons enable dashboard

# 설치 후
minikube addons list
#|ingress |minikube |enabled ✅ |Kubernetes |

# pod 확인 (-n : 네임스페이스 조회)
kubectl get pods -n ingress-nginx
# NAME                                       READY   STATUS      RESTARTS   AGE
# ingress-nginx-admission-create-zhxrl       0/1     Completed   0          2m36s
# ingress-nginx-admission-patch-rsdbw        0/1     Completed   0          2m36s
# ingress-nginx-controller-67c5cb88f-rn85w   1/1     Running     0          2m36s

# 서비스 상태 확인
kubectl get svc -n ingress-nginx
#NAME                                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
#ingress-nginx-controller             NodePort    10.108.145.255   <none>        80:32301/TCP,443:30247/TCP   4m5s
#ingress-nginx-controller-admission   ClusterIP   10.98.128.72     <none>        443/TCP                      4m5s

# ingress 서비스 YAML 확인용 명령어
kubectl get pod -n ingress-nginx -l app.kubernetes.io/component=controller -o yaml
# addon 으로 설치 시 아래와 같이 포트 사용됨을 확인
- containerPort: 80
        hostPort: 80

# ingress 호출 테스트
curl $(minikube ip):80
```

#### ❗추가 내용(소스 로직에 따라 선택사항)

> **클라이언트 IP 를 채번하는 로직을 위해서는 XFF 헤더 설정이 필요**
>
> **💻XFF(X-Forwarded-For)란?** > **로드벨런서 혹은 프록시 서버를 경유할 경우 소스 코드 상에서 클라이언트 요청에서 IP를 채번할 때 로드벨런서나 프록시 서버의 주소로 채번하기 때문에 클라이언트 IP 채번을 위한 표준 헤더**

```bash
# minikube ingress 설정 확인
kubectl -n ingress-nginx get configmap ingress-nginx-controller -o yaml
apiVersion: v1
data:
  hsts: "false"
  #use-forwarded-headers: "true" => 해당 설정이 되어 있는지 확인 후 없는 경우 추가

# 수정 명령어(vi 편집기 수정)
kubectl -n ingress-nginx edit configmap ingress-nginx-controller

# minikube ingress 설정 확인
kubectl -n ingress-nginx get configmap ingress-nginx-controller -o yaml
apiVersion: v1
data:
  hsts: "false"
  use-forwarded-headers: "true"

# 인그레스 deploy 재기동
kubectl -n ingress-nginx rollout restart deployment ingress-nginx-controller

# 위 사항 진행 후 앱에서 XFF(X-Forwarded-For) 해더를 사용하게 필터 혹은 채번 로직을 수정
```

### 04 영구적인 볼륨 생성

> **pod 끼리 같은 볼륨을 사용하는 경우 nfs 스토리지가 있어야 한다**
> => **nfs 스토리지가 별도로 없는 경우 아래와 같이 nfs 유틸로 서버를 생성한다**

#### 1) NFS 서버 설치 (Rocky Linux)

##### (1) NFS 유틸 설치

```bash
sudo dnf install -y nfs-utils
```

##### (2) NFS 서비스 활성화 및 시작

```bash
sudo systemctl enable --now nfs-server
sudo systemctl start nfs-server
```

##### (3) NFS 공유 디렉토리 생성 및 export 설정

```bash
sudo mkdir -p /nfs
sudo chown -R nobody:nobody /nfs
sudo chmod 777 /nfs
```

- /etc/exports 에 nfs 디렉토리 설정

```bash
echo "/nfs *(rw,sync,no_subtree_check,no_root_squash)" | sudo tee -a /etc/exports
```

- exportfs 적용

```bash
sudo exportfs -rav
```

##### (4) NFS 서버 확인

```bash
sudo exportfs -v
```

- 출력에 /nfs 가 잘 나오면 OK 이제 프로그램에 알맞은 PVC와 PV를 셋팅하고 적용하면된다

##### (5) PVC/PV 예제

```yaml
# NFS PVC/PV 예제
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 50Gi
  accessModes:
    # NFS는 여러 노드 동시 ReadWrite 가능
    # (ReadWriteOnce|ReadWriteMany)
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    # NFS 서버의 IP 주소 또는 호스트 이름
    server: 192.168.0.69
    # NFS 서버에서 공유하는 디렉토리 경로
    path: /data/pv/
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  # 수동 할당 시 SC "" 으로 설정
  storageClassName: ""
---
```

### XX. TOMCAT 간의 세션 클러스터링

> **POD가 여러 개 생성될 경우 WAS 간 세션 문제가 발생될 수 있다.** > **따라서 TOMCAT 클러스터링 작업을 해야한다.** > **이를 위해 REDIS DB를 생성하고 TOMCAT의 세션 정보를 저장하도록 구성이 필요하다.**

```bash
# 헬름차트를 통해 쿠버네티스에 세션 공유용 redis 배포
  helm repo add bitnami https://charts.bitnami.com/bitnami
  helm install redis bitnami/redis --set architecture=standalone
# redis 비밀번호 확인
  kubectl get secret --namespace default redis -o jsonpath="{.data.redis-password}" | base64 -d
```

> **helm으로 설치된 redis 비밀번호를 deployment 환경변수에 셋팅**

```yaml
env:
  - name: REDIS_PASSWORD
    valueFrom:
      secretKeyRef:
        name: redis # Secret 이름
        key: redis-password # Secret key 이름 (대소문자 정확히 맞춰야 함)
```

> **톰켓의 context.xml 에 아래와 같이 설정**

```xml
<Context>
  <Valve className="tomcat.request.session.redis.SessionHandlerValve" />
  <Manager className="tomcat.request.session.redis.SessionManager" />
</Context>
```

### XX. 쿠버네티스용 DB 생성

```bash
# 아래 작성글을 참조하여 작업 진행
# Blog
https://thekoguryo.github.io/oracle-cloudnative/databases/oracle-database/2.oracle-database-operator/
# github
https://github.com/oracle/oracle-database-operator

#cert-manager 설치
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.yaml
#cert-manager 기동 확인
kubectl get pods -n cert-manager
#위 명령어로 기동 확인 후에 아래 진행해야 정확히 인증이 되어 설치가 가능하다.
#NAME                                      READY   STATUS    RESTARTS   AGE
#cert-manager-767f578ff-twhhh              1/1     Running   0          79s
#cert-manager-cainjector-c7fdb4dbf-dx26l   1/1     Running   0          79s
#cert-manager-webhook-768bf9d966-s9mg8     1/1     Running   0          79s

#OraOperator 설치
kubectl apply -f https://raw.githubusercontent.com/oracle/oracle-database-operator/main/oracle-database-operator.yaml
#OraOperator 기동 확인
kubectl get pods -n oracle-database-operator-system

#oracle-database-operator를 설치
#두가지 선택지가 있음(클러스터단위|네임스페이스단위)
#아래는 클러스터 단위설정으로 진행
# 1)ClusterRoleBinding 설정
# https://github.com/oracle/oracle-database-operator/blob/main/rbac/cluster-role-binding.yaml
# 위 URL 참조 파일 생성 후 적용
kubectl apply -f cluster-role-binding.yaml
# 2)ClusterRole and ClusterRoleBinding for NodePort services 설정(로드벨런서 서비스는 필요 없음)
# https://github.com/oracle/oracle-database-operator/blob/main/rbac/node-rbac.yaml
# 위 URL 참조 파일 생성 후 적용
kubectl apply -f node-rbac.yaml
# 3)oracle-database-operator 설치
# https://github.com/oracle/oracle-database-operator/blob/main/oracle-database-operator.yaml
# 위 URL 참조 파일 생성 후 적용
kubectl get pod -n oracle-database-operator-system
# 상태 체크
kubectl get pod -n oracle-database-operator-system
#NAME                                                           READY   STATUS    RESTARTS   AGE
#oracle-database-operator-controller-manager-7898b79f6b-28x2f   1/1     Running   0          68s
#oracle-database-operator-controller-manager-7898b79f6b-fzsrc   1/1     Running   0          68s
#oracle-database-operator-controller-manager-7898b79f6b-wzwzv   1/1     Running   0          68s

# oracle 사용 secret 셋팅(오라클 패스워드 설정)
## Oracle Database Free Admin password secret
apiVersion: v1
kind: Secret
metadata:
  name: freedb-admin-secret
  namespace: default
type: Opaque
stringData:
  ## 해당부분 DB password 셋팅
  oracle_pwd: your_DB_password

# oracle_free SIDB(싱글인스턴스DB) 버전 설치
# https://github.com/oracle/oracle-database-operator/blob/main/config/samples/sidb/singleinstancedatabase_free.yaml
# 위 URL 참조(싱글인스턴스DB free 버전) 파일 생성 후 적용
# minikube 설치 시 스토리지클래스 standard 로 설정
# free 버전은 레플리카 수 1개 고정
kubectl apply -f singleinstancedatabase_free.yaml
# 상태 체크1
kubectl get events --sort-by='.metadata.creationTimestamp' -A
# Pulling image "container-registry.oracle.com/database/free:latest"
# 상태 체크2
kubectl get SingleInstanceDatabase
#NAME            EDITION   STATUS    ROLE          VERSION       CONNECT STR   TCPS CONNECT STR   OEM EXPRESS URL
#freedb-sample   Free      Pending   Unavailable   Unavailable   Unavailable   Unavailable        Unavailable
# Pending -> Healthy 로 되면 성공
# 중간에 unhealthy 나 updating 상태 시 대기 혹은 아래 명령어로 상태 체크3
kubectl describe SingleInstanceDatabase/freedb-sample
# 이미지 크기가 커서 다소 시간이 소요됩니다.
 kubectl get SingleInstanceDatabase
# NAME            EDITION   STATUS    ROLE      VERSION        CONNECT STR               TCPS CONNECT STR   OEM EXPRESS URL
# freedb-sample   Free      Healthy   PRIMARY   23.8.0.25.04   192.168.49.2:32532/FREE   Unavailable        Unavailable
# pod 확인
kubectl get pod -n default
#NAME                  READY   STATUS    RESTARTS   AGE
#freedb-sample-7ww2z   1/1     Running   0          11m

# DB 접속 확인
sqlplus sys/your_DB_password@192.168.49.2:32532/FREE as sysdba

# 외부에서 내부 minikube ip 의 오라클에 붙는 방법 예시
sudo socat TCP-LISTEN:1521,fork TCP:192.168.49.2:32532
# 혹은 nginx stream 프록시 사용

```

### 05. 배포모듈 이미지화

### 06. deployment 생성

### 07. pod 생성

`kubectl expose deployment nginx-deployment --type=NodePort --port=80`

### 06. CI/CD 구성(GITHUB 웹훅 및 젠킨스 사용)
